{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1spl7OmBDLC2hOeAL8s2N8lmKZkRoMsDD",
      "authorship_tag": "ABX9TyO744u8moId0Bt3SRx42NID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sioulruble/GenDL/blob/main/advanced_architectures/LAB1_GENDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1jwmWWvIjZQ",
        "outputId": "c2933262-d1c2-4fa7-9ed5-8d927ba7200b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 16, 16]             416\n",
            "            Conv2d-2             [-1, 32, 8, 8]           4,640\n",
            "            Linear-3                   [-1, 64]           2,112\n",
            "            Linear-4                    [-1, 2]             130\n",
            "================================================================\n",
            "Total params: 7,298\n",
            "Trainable params: 7,298\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.08\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it 0: J() = 0.695\n",
            "it 1: J() = 0.692\n",
            "it 2: J() = 0.679\n",
            "it 3: J() = 0.671\n",
            "it 4: J() = 0.568\n",
            "it 5: J() = 0.341\n",
            "it 6: J() = 0.258\n",
            "it 7: J() = 0.191\n",
            "it 8: J() = 0.147\n",
            "it 9: J() = 0.111\n",
            "it 10: J() = 0.088\n",
            "it 11: J() = 0.077\n",
            "Error %: 1.915114\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import gzip\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Téléchargement du fichier de données\n",
        "#!wget http://dihana.cps.unizar.es/~cadrete/gen/p1_data1.pkl.gz\n",
        "\n",
        "# Chargement des données\n",
        "with gzip.open('/home/p1_data1.pkl.gz', 'rb') as f:\n",
        "    x_train, y_train, x_test, y_test = pickle.load(f)\n",
        "\n",
        "x_train = x_train.astype(np.float32) / 255\n",
        "x_test = x_test.astype(np.float32) / 255\n",
        "\n",
        "# Création d'un dataset personnalisé\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "trainset = CustomDataset(x_train, y_train)\n",
        "testset = CustomDataset(x_test, y_test)\n",
        "\n",
        "# Définition du modèle\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, di=1, h1=16, h2=32, h3=64, C=2):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(di, h1, kernel_size=5, padding=2, stride=2)\n",
        "        self.conv2 = torch.nn.Conv2d(h1, h2, kernel_size=3, padding=1, stride=2)\n",
        "        self.fc1 = torch.nn.Linear(h2, h3)\n",
        "        self.fc2 = torch.nn.Linear(h3, C)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.mean([2, 3])\n",
        "        x = F.relu(self.fc1(x))\n",
        "        o = self.fc2(x)\n",
        "        return o\n",
        "\n",
        "    def predict(self, x):\n",
        "        return F.softmax(self.forward(x), dim=1)\n",
        "\n",
        "# Initialisation du modèle et affichage du résumé\n",
        "model = Net().cuda()\n",
        "summary(model, (1, 32, 32))\n",
        "\n",
        "# Paramètres d'entraînement\n",
        "batch_size = 32\n",
        "nb_its = 12\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "J = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.6, weight_decay=1e-5)\n",
        "J_it = np.zeros(nb_its)\n",
        "\n",
        "# Boucle d'entraînement\n",
        "for i in range(nb_its):\n",
        "    k = 0\n",
        "    for x, y in trainloader:\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        model.zero_grad()\n",
        "        o = model(x)\n",
        "        loss = J(o, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        J_it[i] += loss.item()\n",
        "        k += 1\n",
        "    J_it[i] /= k\n",
        "    print(\"it %d: J() = %.3f\" % (i, J_it[i]))\n",
        "\n",
        "# Test du modèle\n",
        "x = torch.tensor(x_test, dtype=torch.float32).cuda()\n",
        "o = model(x).detach().cpu().numpy()\n",
        "o_max = np.argmax(o, axis=1)\n",
        "err = np.sum(y_test != o_max)\n",
        "print('Error %%: %f' % (err / len(y_test) * 100))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# **Customized RNN from a CNN**\n",
        "\n",
        "\n",
        "https://medium.com/@chen-yu/building-a-customized-residual-cnn-with-pytorch-471810e894ed\n"
      ],
      "metadata": {
        "id": "rFDljfautBs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "from IPython.display import Image\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, di=1, h1=16, h2=32, h3=64, C=2) :\n",
        "        super().__init__()\n",
        "\n",
        "        # Conv 5x5\n",
        "        self.conv5x5_1 = nn.Conv2d(di, h1, kernel_size=5, padding='same', bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(h1)\n",
        "\n",
        "        self.conv5x5_2 = nn.Conv2d(h1, h2, kernel_size=5, padding='same', bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(h2)\n",
        "\n",
        "        # Conv 1x1\n",
        "        self.conv1x1 = nn.Conv2d(h2, h3, kernel_size=1, bias=False)\n",
        "        self.bn1x1 = nn.BatchNorm2d(h3)\n",
        "        # Conv 3x3 sur la branche parallèle\n",
        "        self.conv3x3_1 = nn.Conv2d(h2, h3, kernel_size=3, padding='same', bias=False)  # h2 en entrée, h3 en sortie\n",
        "        self.bn3x3_1 = nn.BatchNorm2d(h3)\n",
        "        self.conv3x3_2 = nn.Conv2d(h3, h3, kernel_size=3, padding='same', bias=False)\n",
        "        self.bn3x3_2 = nn.BatchNorm2d(h3)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc = nn.Linear(h3, C)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.conv5x5_1(x))\n",
        "        x = self.relu(self.bn2(self.conv5x5_2(x)))\n",
        "\n",
        "        branch1 = self.bn1x1(self.conv1x1(x))\n",
        "\n",
        "        branch2 = self.bn3x3_1(self.conv3x3_1(x))\n",
        "        branch2 = self.relu(self.bn3x3_2(self.conv3x3_2(branch2)))\n",
        "\n",
        "        # Combiner les branches\n",
        "        x = self.relu(branch1 + branch2)\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.relu(self.forward(x), dim=1)\n",
        "\n",
        "\n",
        "# Initialisation et visualisation\n",
        "residual_block = ResidualBlock().cuda()\n",
        "\n",
        "x = torch.randn(1,1,32, 32)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "residual_block = residual_block.to(device)\n",
        "x = x.to(device)\n",
        "summary(residual_block,(1,32, 32))\n",
        "\n",
        "# Générer le graphe\n",
        "y = residual_block(x)\n",
        "# dot = make_dot(y, params=dict(residual_block.named_parameters()))\n",
        "\n",
        "# # Sauvegarder le graphe en format PNG\n",
        "# dot.render(\"residual_block\", format=\"png\")\n",
        "\n",
        "# # Afficher l'image générée dans Colab\n",
        "# Image(\"residual_block.png\")\n",
        "\n",
        "!pip install onnx\n",
        "torch.onnx.export(residual_block,x,'model.onnx')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AmIvs-DtUzr",
        "outputId": "5767dabf-abb9-4e3c-9fbf-7dd90a7d217f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             400\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 32, 32, 32]          12,800\n",
            "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
            "              ReLU-5           [-1, 32, 32, 32]               0\n",
            "            Conv2d-6           [-1, 64, 32, 32]           2,048\n",
            "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
            "            Conv2d-8           [-1, 64, 32, 32]          18,432\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "             ReLU-12           [-1, 64, 32, 32]               0\n",
            "             ReLU-13           [-1, 64, 32, 32]               0\n",
            "AdaptiveAvgPool2d-14             [-1, 64, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 71,024\n",
            "Trainable params: 71,024\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 5.00\n",
            "Params size (MB): 0.27\n",
            "Estimated Total Size (MB): 5.28\n",
            "----------------------------------------------------------------\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation du modèle\n",
        "model = ResidualBlock().cuda()\n",
        "\n",
        "# Paramètres d'entraînement\n",
        "batch_size = 32\n",
        "nb_its = 12\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Boucle d'entraînement\n",
        "for epoch in range(nb_its):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.3f}\")\n",
        "    # Test du modèle\n",
        "x = torch.tensor(x_test, dtype=torch.float32).cuda()\n",
        "o = model(x).detach().cpu().numpy()\n",
        "o_max = np.argmax(o, axis=1)\n",
        "err = np.sum(y_test != o_max)\n",
        "print('Error %%: %f' % (err / len(y_test) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRd-E2IdXamm",
        "outputId": "5572a738-981c-4dd3-c28e-c7705797d890"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.971\n",
            "Epoch 2, Loss: 2.049\n",
            "Epoch 3, Loss: 1.256\n",
            "Epoch 4, Loss: 0.801\n",
            "Epoch 5, Loss: 0.539\n",
            "Epoch 6, Loss: 0.387\n",
            "Epoch 7, Loss: 0.289\n",
            "Epoch 8, Loss: 0.226\n",
            "Epoch 9, Loss: 0.186\n",
            "Epoch 10, Loss: 0.153\n",
            "Epoch 11, Loss: 0.133\n",
            "Epoch 12, Loss: 0.111\n",
            "Error %: 0.362319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention Model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8agCf2PsyX6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Un_UHZLUZln5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}